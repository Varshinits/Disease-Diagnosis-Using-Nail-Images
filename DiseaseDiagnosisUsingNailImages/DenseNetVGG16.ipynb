{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=(1./255),horizontal_flip=True,shear_range=0.2)\n",
    "test_gen = ImageDataGenerator(rescale=(1./255))  #--> (0 to 255) convert to (0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 655 images belonging to 17 classes.\n",
      "Found 183 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory('Dataset(original)/train',\n",
    "                                      target_size=(224, 224),\n",
    "                                      class_mode='categorical', \n",
    "                                      batch_size=8)\n",
    "test = test_gen.flow_from_directory('Dataset(original)/test',\n",
    "                                    target_size=(224, 224),\n",
    "                                      class_mode='categorical', \n",
    "                                      batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Darier_s disease': 0,\n",
       " 'Muehrck-e_s lines': 1,\n",
       " 'aloperia areata': 2,\n",
       " 'beau_s lines': 3,\n",
       " 'bluish nail': 4,\n",
       " 'clubbing': 5,\n",
       " 'eczema': 6,\n",
       " 'half and half nailes (Lindsay_s nails)': 7,\n",
       " 'koilonychia': 8,\n",
       " 'leukonychia': 9,\n",
       " 'onycholycis': 10,\n",
       " 'pale nail': 11,\n",
       " 'red lunula': 12,\n",
       " 'splinter hemmorrage': 13,\n",
       " 'terry_s nail': 14,\n",
       " 'white nail': 15,\n",
       " 'yellow nails': 16}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters and configurations\n",
    "num_classes = 17\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your DenseNet-VGG16 hybrid model architecture\n",
    "def DenseNetVGG16(num_classes):\n",
    "    # Load pre-trained DenseNet and VGG16 models\n",
    "    densenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in densenet.layers:\n",
    "        layer.trainable = False\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Combine DenseNet and VGG16 models\n",
    "    input_layer = tf.keras.Input(shape=(224, 224, 3))\n",
    "    densenet_output = densenet(input_layer)\n",
    "    vgg16_output = vgg16(input_layer)\n",
    "\n",
    "    # Add global average pooling layer\n",
    "    densenet_output = GlobalAveragePooling2D()(densenet_output)\n",
    "    vgg16_output = GlobalAveragePooling2D()(vgg16_output)\n",
    "\n",
    "    # Concatenate DenseNet and VGG16 outputs\n",
    "    combined_output = tf.keras.layers.concatenate([densenet_output, vgg16_output])\n",
    "\n",
    "    # Add a fully connected layer\n",
    "    dense = Dense(units=128, activation='relu')(combined_output)\n",
    "\n",
    "    # Add output layer\n",
    "    output = Dense(units=num_classes, activation='softmax')(dense)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the nail image dataset\n",
    "# Ensure that you have a data generator providing batches of image-label pairs\n",
    "# Initialize your DenseNet-VGG16 hybrid model\n",
    "model = DenseNetVGG16(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " densenet121 (Functional)       (None, 7, 7, 1024)   7037504     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " vgg16 (Functional)             (None, 7, 7, 512)    14714688    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['densenet121[0][0]']            \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 512)         0           ['vgg16[0][0]']                  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1536)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'global_average_pooling2d_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          196736      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 17)           2193        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,951,121\n",
      "Trainable params: 198,929\n",
      "Non-trainable params: 21,752,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer with a specific learning rate\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "82/82 [==============================] - 183s 2s/step - loss: 2.7966 - accuracy: 0.1282 - val_loss: 2.3961 - val_accuracy: 0.2787\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 114s 1s/step - loss: 2.2773 - accuracy: 0.3084 - val_loss: 1.9984 - val_accuracy: 0.3989\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 102s 1s/step - loss: 1.9202 - accuracy: 0.3985 - val_loss: 1.6590 - val_accuracy: 0.5574\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 103s 1s/step - loss: 1.6496 - accuracy: 0.5176 - val_loss: 1.3833 - val_accuracy: 0.6066\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 104s 1s/step - loss: 1.4219 - accuracy: 0.5710 - val_loss: 1.0932 - val_accuracy: 0.7377\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 106s 1s/step - loss: 1.2452 - accuracy: 0.6565 - val_loss: 1.0620 - val_accuracy: 0.7158\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 106s 1s/step - loss: 1.0598 - accuracy: 0.6855 - val_loss: 0.8482 - val_accuracy: 0.8142\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.9243 - accuracy: 0.7481 - val_loss: 0.7064 - val_accuracy: 0.8033\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.8068 - accuracy: 0.7817 - val_loss: 0.6390 - val_accuracy: 0.8251\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.7148 - accuracy: 0.8031 - val_loss: 0.5976 - val_accuracy: 0.8251\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.6230 - accuracy: 0.8443 - val_loss: 0.4926 - val_accuracy: 0.8525\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 109s 1s/step - loss: 0.5399 - accuracy: 0.8672 - val_loss: 0.4048 - val_accuracy: 0.8907\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 108s 1s/step - loss: 0.4700 - accuracy: 0.8855 - val_loss: 0.3436 - val_accuracy: 0.9180\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 106s 1s/step - loss: 0.4077 - accuracy: 0.9084 - val_loss: 0.2674 - val_accuracy: 0.9508\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.3516 - accuracy: 0.9130 - val_loss: 0.2142 - val_accuracy: 0.9781\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.2971 - accuracy: 0.9405 - val_loss: 0.1919 - val_accuracy: 0.9781\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 111s 1s/step - loss: 0.2626 - accuracy: 0.9496 - val_loss: 0.1567 - val_accuracy: 0.9891\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 111s 1s/step - loss: 0.2395 - accuracy: 0.9481 - val_loss: 0.2373 - val_accuracy: 0.9454\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 114s 1s/step - loss: 0.1987 - accuracy: 0.9679 - val_loss: 0.1418 - val_accuracy: 0.9836\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 111s 1s/step - loss: 0.1842 - accuracy: 0.9710 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 113s 1s/step - loss: 0.1526 - accuracy: 0.9695 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 111s 1s/step - loss: 0.1256 - accuracy: 0.9817 - val_loss: 0.0788 - val_accuracy: 0.9945\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 109s 1s/step - loss: 0.1190 - accuracy: 0.9710 - val_loss: 0.0812 - val_accuracy: 0.9891\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 109s 1s/step - loss: 0.1068 - accuracy: 0.9832 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 112s 1s/step - loss: 0.0894 - accuracy: 0.9832 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 109s 1s/step - loss: 0.0796 - accuracy: 0.9893 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 108s 1s/step - loss: 0.0698 - accuracy: 0.9893 - val_loss: 0.0548 - val_accuracy: 0.9945\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 109s 1s/step - loss: 0.0610 - accuracy: 0.9893 - val_loss: 0.0678 - val_accuracy: 0.9836\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 108s 1s/step - loss: 0.0585 - accuracy: 0.9893 - val_loss: 0.0220 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ae6953cd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train,epochs=num_epochs,validation_data=test, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('DenseNetVGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('DenseNetVGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Dataset-3/Test/Leukonychia/21.PNG',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "terry_s nail_WhiteNails\n"
     ]
    }
   ],
   "source": [
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img,axis=0)\n",
    "model.predict(img)\n",
    "pred = np.argmax(model.predict(img))\n",
    "output = ['Darier_s disease','Muehrck-e_s lines','Onychogryphosis','Onycholycis_NailPsoriasis',\n",
    "          'aloperia areata','beau_s lines','bluish nail', 'clubbing','eczema','half and half nailes (Lindsay_s nails)',\n",
    "          'koilonychia','leukonychia','pale nail','red lunula',\n",
    "          'splinter hemmorrage_Acral Lentiginous Melanoma',\n",
    "          'terry_s nail_WhiteNails','yellow nails']\n",
    "print(output[pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
